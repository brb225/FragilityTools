% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/front.R
\name{get.traditional.ss.params}
\alias{get.traditional.ss.params}
\title{Get equivalent parameters in traditional power calculation}
\usage{
get.traditional.ss.params(
  alpha,
  pi,
  delta,
  n,
  get.sample.alt.f,
  get.p.val,
  verbose = FALSE,
  cl = NULL,
  limits = c(0, 1),
  nsim = 10000,
  mc.iters = 100,
  delta.iters = 100
)
}
\arguments{
\item{alpha}{a numeric for the significance cutoff}

\item{pi}{a numeric for the power of the p value based test}

\item{delta}{a numeric for the effect size, the difference between the event probability in
the first and second group}

\item{n}{a numeric for the designed sample size}

\item{get.sample.alt.f}{a function to get a two group sample under the alternative, depending on the sample size
and the effect size}

\item{get.p.val}{a function which inputs a contingency table and outputs a p value}

\item{verbose}{a boolean for whether to print status updates while running}

\item{cl}{a cluster from the \code{parallel} package, not currently supported}

\item{nsim}{the number of draws used to estimate the distribution of the p value under the alternative, by default 100000}

\item{mc.iters}{the number of draws used to estimate the distribution of the p value under the alternative in a noisy root finding
algorithm, by default 100}

\item{delta.iters}{the number of iterations used of the root finding algorithm to find the effect size delta which designs the same
sample size. The overall output is the median over each of the delta.iters iterations.}
}
\value{
a length 3 numeric vector containing the alpha, pi, and delta for which if the other two are at the input values, the input
sample size would be designed.
}
\description{
This function is designed to help understand the role of the fragility index based sample size calculation in
terms of parameters involved in usual p value based sample size calculations. The primary inputs into the function
are the usual significance cutoff, power, and effect size, together with the fragility index based sample size. The
function then considers the question "how low must the significance cutoff be to reach the input sample size, when all
other inputs are fixed at the same value". Then it repeats the question for each input in turn.
}
\examples{
get.p.val <- function(mat) {
  pearson.test.stata <- function(mat) {
    n1 <- sum(mat[1, ])
    n2 <- sum(mat[2, ])
    p1 <- mat[1, 1] / n1
    p2 <- mat[2, 1] / n2
    pbar <- (n1 * p1 + n2 * p2) / (n1 + n2)
    ts <- (p1 - p2) / sqrt(pbar * (1 - pbar) * (1 / n1 + 1 / n2))
    p_value <- 2 * pnorm(abs(ts), lower.tail = FALSE)
    return(ifelse(is.nan(p_value), 1, p_value))
  }
  suppressWarnings(p <- pearson.test.stata(mat))
  return(ifelse(is.na(p), 1, p))
}
get.sample.alt.f <- function(ss, delta) {
  draw.binom(ss,
    theta1 = 0.08, theta2 = 0.08 + delta,
    row.prop = 1 / 2, matrix = TRUE
  )
}
get.traditional.ss.params(0.05, .8, .06, 1850, get.sample.alt.f, get.p.val = get.p.val)

}
